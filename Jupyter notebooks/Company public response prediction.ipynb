{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:20:53.118937Z",
     "start_time": "2024-04-27T23:20:52.407318Z"
    }
   },
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "from nltk import SnowballStemmer\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from pyodbc import lowercase\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from spacy.lang.en.examples import sentences\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define a stemming tokenizer function\n",
    "def stemming_tokenizer(str_input):\n",
    "    \"\"\"\n",
    "    This function takes a string input and returns a list of stemmed words.\n",
    "    \"\"\"\n",
    "    words = re.sub(r\"[^A-Za-z]\", \" \", str_input).lower().split()\n",
    "    words = [snow_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# Define a function to create a document frequency matrix\n",
    "def TAB_dfm(text, ngrams_range = (1,2), stop_words = 'english', min_prop = .01, max_features=None):\n",
    "    \"\"\"\n",
    "    This function takes a text input and returns a document frequency matrix and a matrix.\n",
    "    \"\"\"\n",
    "    if stop_words == 'english':\n",
    "        vec = CountVectorizer(\n",
    "            tokenizer = stemming_tokenizer,\n",
    "            stop_words = stop_words,\n",
    "            ngram_range=ngrams_range,\n",
    "            min_df=min_prop,\n",
    "            max_features=max_features,\n",
    "            token_pattern='(?u)\\\\b\\\\w+\\\\b'\n",
    "            )\n",
    "    else:\n",
    "        vec = CountVectorizer(\n",
    "            tokenizer = stemming_tokenizer,\n",
    "            ngram_range=ngrams_range,\n",
    "            min_df=min_prop,\n",
    "            max_features=max_features,\n",
    "            token_pattern='(?u)\\\\b\\\\w+\\\\b'\n",
    "        )\n",
    "\n",
    "    mtx = vec.fit_transform(text).todense()\n",
    "    df = round(pd.DataFrame(mtx, columns=vec.get_feature_names_out()),2)\n",
    "    return df, mtx\n",
    "\n",
    "# Define a function to calculate Kendall's tau accuracy\n",
    "def kendall_acc(x,y,percentage = True):\n",
    "    \"\"\"\n",
    "    This function takes two inputs x and y and returns Kendall's tau accuracy.\n",
    "    \"\"\"\n",
    "    tau, p_value = stats.kendalltau(x, y)\n",
    "    tau_acc = .5+tau/2\n",
    "    tau_se = np.sqrt((tau_acc*(1 - tau_acc))/len(x))\n",
    "    report = pd.DataFrame([tau_acc, tau_acc - 1.96 * tau_se, tau_acc + 1.96 * tau_se],\n",
    "                            index = ['acc', 'lower', 'upper']).T\n",
    "    report = round(report,4)\n",
    "\n",
    "    if percentage is True:\n",
    "        report = report * 100\n",
    "\n",
    "    return report\n",
    "\n",
    "# Define a function to calculate Jaccard similarity\n",
    "def jaccard_sim(str1, str2):\n",
    "    \"\"\"\n",
    "    This function takes two string inputs and returns the Jaccard similarity.\n",
    "    \"\"\"\n",
    "    a = set(stemming_tokenizer(str1))\n",
    "    b = set(stemming_tokenizer(str2))\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "# Define a function to calculate Euclidean distance\n",
    "def euclidian_dist(docs, y = 0):\n",
    "    \"\"\"\n",
    "    This function takes a list of documents and an index y and returns a list of Euclidean distances.\n",
    "    \"\"\"\n",
    "    _, features = np.asarray(TAB_dfm(docs))\n",
    "    distances = [round(float(euclidean_distances([features[y]], [f])),2) for f in features]\n",
    "    return distances\n",
    "\n",
    "# Define a function to calculate cosine similarity\n",
    "def cosine_sim(docs, y = 0):\n",
    "    \"\"\"\n",
    "    This function takes a list of documents and an index y and returns a list of cosine similarities.\n",
    "    \"\"\"\n",
    "    _, features = np.asarray(TAB_dfm(docs, stop_words = False))\n",
    "    distances = [round(float(cosine_similarity([features[y]], [f])),2) for f in features]\n",
    "    return distances\n",
    "\n",
    "# Define a function to parse text using Spacy\n",
    "def spacy_parse(text):\n",
    "    \"\"\"\n",
    "    This function takes a text input and returns a DataFrame with parsed information.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    rows = [[t.text, t.lemma_, t.pos_, t.tag_, t.dep_, spacy.explain(t.pos_), t.is_stop] for t in doc]\n",
    "    cols = (\"text\", \"lemma\", \"POS\", \"Tag\",\"Dep\",\"explain\", \"stopword\")\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "    return df\n",
    "\n",
    "# Define a function to parse lemmas\n",
    "def lemmas_parse(text):\n",
    "    \"\"\"\n",
    "    This function takes a text input and returns a string of lemmas.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    lemmas = [t.lemma_ for t in doc\n",
    "              if t.pos_ not in ('SPACE', 'PRON', 'PUNCT', 'NUM', 'SYM')\n",
    "              if t.is_stop == False]\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "# Define a function to create a document frequency matrix from lemmas\n",
    "def lemmas_dfm(texts):\n",
    "    \"\"\"\n",
    "    This function takes a list of texts and returns a document frequency matrix of lemmas.\n",
    "    \"\"\"\n",
    "    dfms_joined = pd.DataFrame()\n",
    "    for text in texts:\n",
    "        text = [lemmas_parse(text)]\n",
    "        if len(text[0]) > 1:\n",
    "            dfm, _ = TAB_dfm(text, ngrams_range=(0,1), stop_words = False)\n",
    "            dfms_joined = dfms_joined.append(dfm)\n",
    "    return dfms_joined\n",
    "\n",
    "# Define a function to parse named entities\n",
    "def ner_parse(text):\n",
    "    \"\"\"\n",
    "    This function takes a text input and returns a DataFrame with parsed named entities.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    rows = [[ent.text, ent.start_char, ent.end_char, ent.label_] for ent in doc.ents]\n",
    "    cols = (\"Text\", \"Start\", \"End\", \"Label\")\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "    return df\n",
    "\n",
    "# Define a function to filter and parse named entities\n",
    "def ner_filter_parse(text):\n",
    "    \"\"\"\n",
    "    This function takes a text input and returns a string of filtered named entities.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    ents = [ent.text for ent in doc.ents\n",
    "            if ent.label_ == 'GPE']\n",
    "    return ' '.join(list(set(ents)))\n",
    "\n",
    "# Define a function to create a document frequency matrix from named entities\n",
    "def ner_dfm(texts):\n",
    "    \"\"\"\n",
    "    This function takes a list of texts and returns a document frequency matrix of named entities.\n",
    "    \"\"\"\n",
    "    dfms_joined = pd.DataFrame()\n",
    "    for text in texts:\n",
    "        text = [ner_filter_parse(text)]\n",
    "        if len(text[0]) > 1:\n",
    "            dfm, _ = TAB_dfm(text, ngrams_range=(0,1), stop_words = False)\n",
    "            dfms_joined = dfms_joined.append(dfm)\n",
    "    return dfms_joined\n",
    "\n",
    "# Define a tokenizer function\n",
    "def tokenizer(str_input):\n",
    "    \"\"\"\n",
    "    This function takes a string input and returns a list of words.\n",
    "    \"\"\"\n",
    "    words = re.sub(r\"[^A-Za-z]\", \" \", str_input).lower().split()\n",
    "    return words\n",
    "\n",
    "# Define a function to create a document frequency matrix from a lookup dictionary\n",
    "def dfm_lookup(text, dict_as_list, ngrams_range = (1,1), min_prop = .01, max_features=None):\n",
    "    \"\"\"\n",
    "    This function takes a text input and a lookup dictionary and returns a document frequency matrix.\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer(\n",
    "        tokenizer = tokenizer,\n",
    "        stop_words = 'english',\n",
    "        ngram_range=ngrams_range,\n",
    "        min_df=min_prop,\n",
    "        max_features=max_features,\n",
    "        token_pattern='(?u)\\\\b\\\\w+\\\\b'\n",
    "        )\n",
    "    mtx = vec.fit_transform(text).todense()\n",
    "    df = round(pd.DataFrame(mtx, columns=vec.get_feature_names_out()),2)\n",
    "    df = df[df.columns.intersection(dict_as_list)]\n",
    "    row_sums = df.sum(axis=1)\n",
    "    return row_sums\n",
    "\n",
    "'''This Python script is used for text processing and analysis. It includes functions for tokenizing and stemming text, creating document frequency matrices, calculating Kendall's tau accuracy, Jaccard similarity, Euclidean distance, and cosine similarity, parsing text and named entities using Spacy, and creating document frequency matrices from lemmas and named entities. It also includes a function for creating a document frequency matrix from a lookup dictionary.'''"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4d14699f3f360ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:20:54.264494Z",
     "start_time": "2024-04-27T23:20:53.119687Z"
    }
   },
   "source": [
    "# vecSmall.csv contains pre-trained word vectors for a small vocabulary.\n",
    "vecSmall = pd.read_csv('vecSmall.csv', index_col= 0)\n",
    "\n",
    "# wfFile.csv contains word frequency information for a specific corpus.\n",
    "wfFile = pd.read_csv('wfFile.csv', index_col= 0)\n",
    "\n",
    "# filtered_dataset.csv contains the main dataset for analysis. The 'low_memory' parameter is set to False to silence dtypes warning.\n",
    "data = pd.read_csv('filtered_dataset.csv', index_col= 0, low_memory=False)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "2bdcf067c2f5dc55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:20:54.274167Z",
     "start_time": "2024-04-27T23:20:54.265823Z"
    }
   },
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Instantiate the ShuffleSplit class with 1 split, a test size of 40%, and a random state of 42 for reproducibility\n",
    "# This will be used to create a random split of the data into training and testing sets\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.4, random_state = 42)\n",
    "\n",
    "# Get the number of splitting iterations in the cross-validator\n",
    "# This is not necessary for the split but can be used to check the number of splits\n",
    "sss.get_n_splits(data)\n",
    "\n",
    "# Generate indices to split data into training and test set\n",
    "# next() is used to get the next item from the iterator\n",
    "train_index, test_index = next(sss.split(data))\n",
    "\n",
    "# Use the generated indices to create the training set\n",
    "# iloc is used for indexing via integers\n",
    "data_train = data.iloc[train_index]\n",
    "\n",
    "# Use the generated indices to create the test set\n",
    "data_test = data.iloc[test_index]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "fc38de48e15f3d24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:20:54.279827Z",
     "start_time": "2024-04-27T23:20:54.274707Z"
    }
   },
   "source": [
    "# Import the lowercase function from the pyodbc library\n",
    "from pyodbc import lowercase\n",
    "\n",
    "# The following code is a Python equivalent to the vecCheck function in the vectorFunctions.R script\n",
    "\n",
    "# Define a pipeline for projecting data into embedding space\n",
    "# The pipeline consists of two steps:\n",
    "# 1. TfidfVectorizer: This is used to convert the text data into a matrix of TF-IDF features.\n",
    "#    The vocabulary is set to the index of the wfFile DataFrame and the lowercase parameter is set to False to keep uppercase characters.\n",
    "# 2. TruncatedSVD: This is used for dimensionality reduction. It transforms the data to have the same number of dimensions as the pre-trained model.\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(vocabulary=wfFile.index, lowercase=False)),  \n",
    "    ('lsa', TruncatedSVD(n_components=vecSmall.shape[1])),  \n",
    "])"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "7dc049ca77fd59c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:21:09.924499Z",
     "start_time": "2024-04-27T23:20:54.280353Z"
    }
   },
   "source": [
    "# Fit the pipeline to the 'Consumer complaint narrative' column of the data DataFrame\n",
    "# This step involves transforming the text data into a matrix of TF-IDF features and then reducing the dimensionality of the data\n",
    "pipeline.fit(data['Consumer complaint narrative'])\n",
    "\n",
    "# Transform the 'Consumer complaint narrative' column of the data DataFrame using the fitted pipeline\n",
    "# This step involves projecting the data into the embedding space\n",
    "vdat = pipeline.transform(data['Consumer complaint narrative'])\n",
    "\n",
    "# Convert the embedded data into a DataFrame\n",
    "# The column names are generated dynamically based on the number of dimensions in the embedded data\n",
    "# Each column represents a dimension in the embedding space\n",
    "vdat = pd.DataFrame(vdat, columns=[f'vec{i+1}' for i in range(vdat.shape[1])])\n",
    "\n",
    "# Print the first 10 rows of the DataFrame\n",
    "# This is used to check the transformed data\n",
    "print(vdat.head(10))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       vec1      vec2      vec3      vec4      vec5      vec6      vec7  \\\n",
      "0  0.212466 -0.042737  0.084530  0.234582 -0.099773 -0.061637  0.058663   \n",
      "1  0.329551 -0.031669 -0.051305 -0.084200  0.057401  0.038061  0.136886   \n",
      "2  0.416767 -0.063856  0.078748  0.057971 -0.059908 -0.073256 -0.056827   \n",
      "3  0.347848 -0.108581 -0.083247 -0.047303  0.275795 -0.014486  0.002261   \n",
      "4  0.254178 -0.043507  0.020654  0.090618 -0.097636 -0.013794 -0.006343   \n",
      "5  0.495647  0.115488  0.200288 -0.012283  0.032888  0.195938 -0.017173   \n",
      "6  0.453418 -0.159387 -0.047675 -0.144897 -0.007143  0.039272 -0.045600   \n",
      "7  0.506661 -0.204375 -0.125888 -0.139932 -0.015730 -0.080862 -0.099955   \n",
      "8  0.476338  0.179721  0.241587  0.031774 -0.016536  0.017355  0.087907   \n",
      "9  0.533134  0.111343  0.187160  0.031704  0.013873  0.188898  0.090014   \n",
      "\n",
      "       vec8      vec9     vec10  ...    vec291    vec292    vec293    vec294  \\\n",
      "0  0.002035 -0.061615 -0.012355  ... -0.056009 -0.023768  0.008212  0.051264   \n",
      "1  0.167399  0.085139 -0.040155  ... -0.043577  0.021924 -0.015487 -0.012814   \n",
      "2  0.002724  0.164222  0.016892  ... -0.000930 -0.012280  0.039937  0.007553   \n",
      "3  0.001086 -0.116583  0.019575  ...  0.005675  0.003537  0.002480 -0.014922   \n",
      "4  0.042713 -0.015163 -0.045401  ... -0.027610  0.008973  0.007670  0.054998   \n",
      "5 -0.050924  0.083704 -0.052131  ... -0.000155  0.022610 -0.015692 -0.004327   \n",
      "6 -0.052550 -0.083591  0.039818  ... -0.006044  0.027036  0.008698  0.038830   \n",
      "7 -0.015847 -0.129722  0.012045  ... -0.001407 -0.006979  0.052682  0.035035   \n",
      "8 -0.105103 -0.013788 -0.098615  ... -0.001866  0.003547  0.015329 -0.002910   \n",
      "9 -0.025468 -0.035508 -0.052599  ... -0.005182 -0.009464 -0.014746  0.016271   \n",
      "\n",
      "     vec295    vec296    vec297    vec298    vec299    vec300  \n",
      "0 -0.027019 -0.017914 -0.015938 -0.064591 -0.005321 -0.006789  \n",
      "1  0.024140  0.033581 -0.012936  0.023254 -0.002005  0.017582  \n",
      "2 -0.003732  0.001576 -0.012773 -0.019525  0.026564  0.031043  \n",
      "3  0.006931 -0.003875  0.008881  0.006380 -0.016759 -0.022547  \n",
      "4 -0.004788 -0.024903 -0.003312  0.002332  0.033979  0.014821  \n",
      "5  0.014448 -0.003519  0.008036 -0.008703 -0.011733  0.014207  \n",
      "6 -0.011580  0.006834 -0.019052 -0.055177 -0.005440 -0.039014  \n",
      "7 -0.046898 -0.020326  0.005111 -0.000119  0.005832  0.019470  \n",
      "8 -0.008621 -0.007783 -0.013012  0.001010  0.016680  0.004606  \n",
      "9 -0.012830  0.002527  0.001935  0.005275 -0.023057 -0.007563  \n",
      "\n",
      "[10 rows x 300 columns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a9806b0bc9160231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:21:09.949657Z",
     "start_time": "2024-04-27T23:21:09.925136Z"
    }
   },
   "source": [
    "# Select the training data from the transformed DataFrame 'vdat' using the training indices\n",
    "vdat_train = vdat.iloc[train_index]\n",
    "\n",
    "# Select the testing data from the transformed DataFrame 'vdat' using the testing indices\n",
    "vdat_test = vdat.iloc[test_index]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "dcbc8b189daf6dea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:21:09.962260Z",
     "start_time": "2024-04-27T23:21:09.950244Z"
    }
   },
   "source": [
    "vdat"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           vec1      vec2      vec3      vec4      vec5      vec6      vec7  \\\n",
       "0      0.212466 -0.042737  0.084530  0.234582 -0.099773 -0.061637  0.058663   \n",
       "1      0.329551 -0.031669 -0.051305 -0.084200  0.057401  0.038061  0.136886   \n",
       "2      0.416767 -0.063856  0.078748  0.057971 -0.059908 -0.073256 -0.056827   \n",
       "3      0.347848 -0.108581 -0.083247 -0.047303  0.275795 -0.014486  0.002261   \n",
       "4      0.254178 -0.043507  0.020654  0.090618 -0.097636 -0.013794 -0.006343   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "55494  0.161414 -0.036910 -0.071791 -0.005227  0.108638  0.007475 -0.125491   \n",
       "55495  0.582511 -0.159423 -0.021621 -0.058352  0.019498  0.098623 -0.051045   \n",
       "55496  0.417243 -0.134113 -0.088882 -0.136230 -0.024750  0.007203 -0.051164   \n",
       "55497  0.259505 -0.015983 -0.044274  0.131172 -0.068296 -0.085412  0.032562   \n",
       "55498  0.465567 -0.174543 -0.052301 -0.083729  0.072768  0.034405 -0.126774   \n",
       "\n",
       "           vec8      vec9     vec10  ...    vec291    vec292    vec293  \\\n",
       "0      0.002035 -0.061615 -0.012355  ... -0.056009 -0.023768  0.008212   \n",
       "1      0.167399  0.085139 -0.040155  ... -0.043577  0.021924 -0.015487   \n",
       "2      0.002724  0.164222  0.016892  ... -0.000930 -0.012280  0.039937   \n",
       "3      0.001086 -0.116583  0.019575  ...  0.005675  0.003537  0.002480   \n",
       "4      0.042713 -0.015163 -0.045401  ... -0.027610  0.008973  0.007670   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "55494  0.069913 -0.135872 -0.025866  ... -0.007753  0.041925 -0.032772   \n",
       "55495 -0.039033 -0.140285 -0.017645  ...  0.007366 -0.032530  0.009722   \n",
       "55496 -0.052207 -0.020424  0.027685  ...  0.008735 -0.019747  0.012631   \n",
       "55497  0.038944  0.145036 -0.034650  ... -0.027390 -0.024985  0.000446   \n",
       "55498 -0.016723 -0.112606  0.003462  ... -0.003449  0.001267 -0.010940   \n",
       "\n",
       "         vec294    vec295    vec296    vec297    vec298    vec299    vec300  \n",
       "0      0.051264 -0.027019 -0.017914 -0.015938 -0.064591 -0.005321 -0.006789  \n",
       "1     -0.012814  0.024140  0.033581 -0.012936  0.023254 -0.002005  0.017582  \n",
       "2      0.007553 -0.003732  0.001576 -0.012773 -0.019525  0.026564  0.031043  \n",
       "3     -0.014922  0.006931 -0.003875  0.008881  0.006380 -0.016759 -0.022547  \n",
       "4      0.054998 -0.004788 -0.024903 -0.003312  0.002332  0.033979  0.014821  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "55494  0.031069 -0.001951 -0.028029 -0.014190 -0.010927  0.030418  0.032375  \n",
       "55495 -0.003164 -0.019724 -0.008250  0.013761 -0.010729  0.017165 -0.016347  \n",
       "55496 -0.045658 -0.017590  0.001285 -0.027635 -0.016317 -0.029945 -0.012813  \n",
       "55497 -0.016602  0.014518  0.012084 -0.000999  0.001971 -0.008067  0.007494  \n",
       "55498 -0.013152 -0.002183  0.008063  0.011010 -0.028820 -0.019066 -0.007064  \n",
       "\n",
       "[55499 rows x 300 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec1</th>\n",
       "      <th>vec2</th>\n",
       "      <th>vec3</th>\n",
       "      <th>vec4</th>\n",
       "      <th>vec5</th>\n",
       "      <th>vec6</th>\n",
       "      <th>vec7</th>\n",
       "      <th>vec8</th>\n",
       "      <th>vec9</th>\n",
       "      <th>vec10</th>\n",
       "      <th>...</th>\n",
       "      <th>vec291</th>\n",
       "      <th>vec292</th>\n",
       "      <th>vec293</th>\n",
       "      <th>vec294</th>\n",
       "      <th>vec295</th>\n",
       "      <th>vec296</th>\n",
       "      <th>vec297</th>\n",
       "      <th>vec298</th>\n",
       "      <th>vec299</th>\n",
       "      <th>vec300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.212466</td>\n",
       "      <td>-0.042737</td>\n",
       "      <td>0.084530</td>\n",
       "      <td>0.234582</td>\n",
       "      <td>-0.099773</td>\n",
       "      <td>-0.061637</td>\n",
       "      <td>0.058663</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>-0.061615</td>\n",
       "      <td>-0.012355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056009</td>\n",
       "      <td>-0.023768</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.051264</td>\n",
       "      <td>-0.027019</td>\n",
       "      <td>-0.017914</td>\n",
       "      <td>-0.015938</td>\n",
       "      <td>-0.064591</td>\n",
       "      <td>-0.005321</td>\n",
       "      <td>-0.006789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.329551</td>\n",
       "      <td>-0.031669</td>\n",
       "      <td>-0.051305</td>\n",
       "      <td>-0.084200</td>\n",
       "      <td>0.057401</td>\n",
       "      <td>0.038061</td>\n",
       "      <td>0.136886</td>\n",
       "      <td>0.167399</td>\n",
       "      <td>0.085139</td>\n",
       "      <td>-0.040155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043577</td>\n",
       "      <td>0.021924</td>\n",
       "      <td>-0.015487</td>\n",
       "      <td>-0.012814</td>\n",
       "      <td>0.024140</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>-0.012936</td>\n",
       "      <td>0.023254</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>0.017582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416767</td>\n",
       "      <td>-0.063856</td>\n",
       "      <td>0.078748</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>-0.059908</td>\n",
       "      <td>-0.073256</td>\n",
       "      <td>-0.056827</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.164222</td>\n",
       "      <td>0.016892</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>-0.012280</td>\n",
       "      <td>0.039937</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>-0.003732</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>-0.012773</td>\n",
       "      <td>-0.019525</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>0.031043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.347848</td>\n",
       "      <td>-0.108581</td>\n",
       "      <td>-0.083247</td>\n",
       "      <td>-0.047303</td>\n",
       "      <td>0.275795</td>\n",
       "      <td>-0.014486</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>-0.116583</td>\n",
       "      <td>0.019575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>-0.014922</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>-0.003875</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>-0.016759</td>\n",
       "      <td>-0.022547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.254178</td>\n",
       "      <td>-0.043507</td>\n",
       "      <td>0.020654</td>\n",
       "      <td>0.090618</td>\n",
       "      <td>-0.097636</td>\n",
       "      <td>-0.013794</td>\n",
       "      <td>-0.006343</td>\n",
       "      <td>0.042713</td>\n",
       "      <td>-0.015163</td>\n",
       "      <td>-0.045401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027610</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.054998</td>\n",
       "      <td>-0.004788</td>\n",
       "      <td>-0.024903</td>\n",
       "      <td>-0.003312</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.033979</td>\n",
       "      <td>0.014821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55494</th>\n",
       "      <td>0.161414</td>\n",
       "      <td>-0.036910</td>\n",
       "      <td>-0.071791</td>\n",
       "      <td>-0.005227</td>\n",
       "      <td>0.108638</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>-0.125491</td>\n",
       "      <td>0.069913</td>\n",
       "      <td>-0.135872</td>\n",
       "      <td>-0.025866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007753</td>\n",
       "      <td>0.041925</td>\n",
       "      <td>-0.032772</td>\n",
       "      <td>0.031069</td>\n",
       "      <td>-0.001951</td>\n",
       "      <td>-0.028029</td>\n",
       "      <td>-0.014190</td>\n",
       "      <td>-0.010927</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.032375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55495</th>\n",
       "      <td>0.582511</td>\n",
       "      <td>-0.159423</td>\n",
       "      <td>-0.021621</td>\n",
       "      <td>-0.058352</td>\n",
       "      <td>0.019498</td>\n",
       "      <td>0.098623</td>\n",
       "      <td>-0.051045</td>\n",
       "      <td>-0.039033</td>\n",
       "      <td>-0.140285</td>\n",
       "      <td>-0.017645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>-0.032530</td>\n",
       "      <td>0.009722</td>\n",
       "      <td>-0.003164</td>\n",
       "      <td>-0.019724</td>\n",
       "      <td>-0.008250</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>-0.010729</td>\n",
       "      <td>0.017165</td>\n",
       "      <td>-0.016347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55496</th>\n",
       "      <td>0.417243</td>\n",
       "      <td>-0.134113</td>\n",
       "      <td>-0.088882</td>\n",
       "      <td>-0.136230</td>\n",
       "      <td>-0.024750</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>-0.051164</td>\n",
       "      <td>-0.052207</td>\n",
       "      <td>-0.020424</td>\n",
       "      <td>0.027685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>-0.019747</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>-0.045658</td>\n",
       "      <td>-0.017590</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>-0.027635</td>\n",
       "      <td>-0.016317</td>\n",
       "      <td>-0.029945</td>\n",
       "      <td>-0.012813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55497</th>\n",
       "      <td>0.259505</td>\n",
       "      <td>-0.015983</td>\n",
       "      <td>-0.044274</td>\n",
       "      <td>0.131172</td>\n",
       "      <td>-0.068296</td>\n",
       "      <td>-0.085412</td>\n",
       "      <td>0.032562</td>\n",
       "      <td>0.038944</td>\n",
       "      <td>0.145036</td>\n",
       "      <td>-0.034650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027390</td>\n",
       "      <td>-0.024985</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>-0.016602</td>\n",
       "      <td>0.014518</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>-0.008067</td>\n",
       "      <td>0.007494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55498</th>\n",
       "      <td>0.465567</td>\n",
       "      <td>-0.174543</td>\n",
       "      <td>-0.052301</td>\n",
       "      <td>-0.083729</td>\n",
       "      <td>0.072768</td>\n",
       "      <td>0.034405</td>\n",
       "      <td>-0.126774</td>\n",
       "      <td>-0.016723</td>\n",
       "      <td>-0.112606</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003449</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>-0.010940</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>-0.002183</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>-0.028820</td>\n",
       "      <td>-0.019066</td>\n",
       "      <td>-0.007064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55499 rows Ã— 300 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "93e5a6f6dab9dd86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ef72d90ff586106",
   "metadata": {},
   "source": [
    "#############################################\n",
    "# Train a vector classifier\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "id": "857762f8d840bae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:21:10.114274Z",
     "start_time": "2024-04-27T23:21:09.964651Z"
    }
   },
   "source": [
    "# Import the LabelEncoder class from the sklearn.preprocessing module\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate the LabelEncoder class\n",
    "# This will be used to encode the 'Company public response' column in the data\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the 'Company public response' column in the training data\n",
    "# This step involves learning the levels of the factor\n",
    "# Then transform the 'Company public response' column in the training data\n",
    "# This step involves converting the levels into numerical labels\n",
    "data_train['Company public response'] = le.fit_transform(data_train['Company public response'])\n",
    "\n",
    "# Transform the 'Company public response' column in the testing data\n",
    "# This step involves converting the levels into numerical labels using the fitted encoder\n",
    "data_test['Company public response'] = le.transform(data_test['Company public response'])\n",
    "\n",
    "# Import the Lasso class from the sklearn.linear_model module\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Instantiate the Lasso class with an alpha of 0.001\n",
    "# This will be used to fit a Lasso model to the data\n",
    "Lasso_vec = Lasso(alpha = 0.001)\n",
    "\n",
    "# Fit the Lasso model to the training data\n",
    "# The 'Company public response' column is the response variable and the 'vdat_train' DataFrame is the predictor variables\n",
    "Lasso_vec.fit(vdat_train,  data_train['Company public response'])\n",
    "\n",
    "# Predict the 'Company public response' column in the testing data using the fitted Lasso model\n",
    "# The 'vdat_test' DataFrame is the predictor variables\n",
    "test_predict = Lasso_vec.predict(vdat_test)\n",
    "\n",
    "# Estimate the accuracy of the Lasso model using Kendall's tau\n",
    "# The 'test_predict' array is the predicted response variable and the 'Company public response' column in the testing data is the actual response variable\n",
    "vec_acc = kendall_acc(test_predict, data_test['Company public response'])\n",
    "\n",
    "# Print the accuracy of the Lasso model\n",
    "print(vec_acc)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc  lower  upper\n",
      "0  64.11  63.48  64.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/ktn1hrps3flfg5b_bszm_lk00000gn/T/ipykernel_10933/2181103015.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train['Company public response'] = le.fit_transform(data_train['Company public response'])\n",
      "/var/folders/2y/ktn1hrps3flfg5b_bszm_lk00000gn/T/ipykernel_10933/2181103015.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['Company public response'] = le.transform(data_test['Company public response'])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ca406d2fd6aecb02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:21:10.126217Z",
     "start_time": "2024-04-27T23:21:10.123840Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "873f6d5aa9937ae5",
   "metadata": {},
   "source": [
    "#############################################\n",
    "# vector embeddings + ngrams\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "id": "b33640dd01e3baf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:22:43.107368Z",
     "start_time": "2024-04-27T23:21:10.127859Z"
    }
   },
   "source": [
    "# Create a document frequency matrix for the 'Consumer complaint narrative' column in the training data\n",
    "# The TAB_dfm function is used to create the document frequency matrix\n",
    "# The second output of the function is not needed, so it is ignored using '_'\n",
    "data_dfm_train, _ = TAB_dfm(data_train['Consumer complaint narrative'])\n",
    "\n",
    "# Create a document frequency matrix for the 'Consumer complaint narrative' column in the testing data\n",
    "# The minimum proportion for a term to be included in the matrix is set to 0\n",
    "data_dfm_test, _ = TAB_dfm(data_test['Consumer complaint narrative'], min_prop = 0)\n",
    "\n",
    "# Create a list of the column names in the training and testing document frequency matrices\n",
    "d = [list(data_dfm_train), list(data_dfm_test)]\n",
    "\n",
    "# Find the intersection of the column names in the training and testing document frequency matrices\n",
    "# This is done to ensure that both matrices have the same columns\n",
    "col_heads = list(set.intersection(*map(set,d)))\n",
    "\n",
    "# Update the training and testing document frequency matrices to only include the intersecting columns\n",
    "# The indices are reset for consistency\n",
    "data_dfm_train= data_dfm_train[col_heads].reset_index(drop = True)\n",
    "data_dfm_test = data_dfm_test[col_heads].reset_index(drop = True)\n",
    "\n",
    "# Reset the indices of the training and testing data in the 'vdat' DataFrame for consistency\n",
    "vdat_train = vdat_train.reset_index(drop = True)\n",
    "vdat_test = vdat_test.reset_index(drop = True)\n",
    "\n",
    "# Combine the training data in the 'vdat' DataFrame and the training document frequency matrix into a single DataFrame\n",
    "# The data is combined along the columns (axis = 1)\n",
    "combined_x_train = pd.concat([vdat_train, data_dfm_train], axis = 1)\n",
    "\n",
    "# Combine the testing data in the 'vdat' DataFrame and the testing document frequency matrix into a single DataFrame\n",
    "# The data is combined along the columns (axis = 1)\n",
    "combined_x_test = pd.concat([vdat_test, data_dfm_test], axis = 1)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e46e12856d7e89d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:22:43.113461Z",
     "start_time": "2024-04-27T23:22:43.111085Z"
    }
   },
   "source": [
    "print(vdat_train.shape)\n",
    "print(data_dfm_train.shape)\n",
    "print(combined_x_train.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33299, 300)\n",
      "(33299, 1318)\n",
      "(33299, 1618)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1f862465a9e16fcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:24:41.694393Z",
     "start_time": "2024-04-27T23:22:43.115153Z"
    }
   },
   "source": [
    "# Import the Lasso class from the sklearn.linear_model module\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Instantiate the Lasso class with an alpha of 0.001\n",
    "# This will be used to fit a Lasso model to the data\n",
    "lasso_all = Lasso(alpha = 0.001)\n",
    "\n",
    "# Fit the Lasso model to the training data\n",
    "# The 'Company public response' column is the response variable and the 'combined_x_train' DataFrame is the predictor variables\n",
    "# The combined_x_train DataFrame contains both the vector embeddings and n-grams features\n",
    "lasso_all.fit(combined_x_train, data_train['Company public response'])\n",
    "\n",
    "# Predict the 'Company public response' column in the testing data using the fitted Lasso model\n",
    "# The 'combined_x_test' DataFrame is the predictor variables\n",
    "test_all_predict = lasso_all.predict(combined_x_test)\n",
    "\n",
    "# Estimate the accuracy of the Lasso model using Kendall's tau\n",
    "# The 'test_all_predict' array is the predicted response variable and the 'Company public response' column in the testing data is the actual response variable\n",
    "ngram_vec_acc = kendall_acc(test_all_predict, data_test['Company public response'])\n",
    "\n",
    "# Print the accuracy of the Lasso model\n",
    "print(ngram_vec_acc)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc  lower  upper\n",
      "0  67.52  66.91  68.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.781e+01, tolerance: 9.494e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "8171bdedab207491",
   "metadata": {},
   "source": [
    "#############################################\n",
    "# ngrams alone\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "id": "5acb954ceccf4134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:29:23.620149Z",
     "start_time": "2024-04-27T23:26:39.885047Z"
    }
   },
   "source": [
    "\n",
    "lasso_dfm = Lasso(alpha = 0.001, max_iter = 10000)\n",
    "\n",
    "# Fit the Lasso model to the training data\n",
    "# The 'Company public response' column is the response variable and the 'data_dfm_train' DataFrame is the predictor variables\n",
    "# The data_dfm_train DataFrame contains the n-grams features\n",
    "lasso_all.fit(data_dfm_train, data_train['Company public response'])\n",
    "\n",
    "# Predict the 'Company public response' column in the testing data using the fitted Lasso model\n",
    "# The 'data_dfm_test' DataFrame is the predictor variables\n",
    "test_dfm_predict = lasso_all.predict(data_dfm_test)\n",
    "\n",
    "# Estimate the accuracy of the Lasso model using Kendall's tau\n",
    "# The 'test_dfm_predict' array is the predicted response variable and the 'Company public response' column in the testing data is the actual response variable\n",
    "ngram_acc = kendall_acc(test_dfm_predict, data_test['Company public response'])\n",
    "\n",
    "# Print the accuracy of the Lasso model\n",
    "print(ngram_acc)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc  lower  upper\n",
      "0  67.17  66.55  67.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.199e+01, tolerance: 9.494e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "4f1c92379d64766f",
   "metadata": {},
   "source": [
    "########################################\n",
    "# Benchmarks\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "id": "1f6665580f6f3e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:25:55.932693Z",
     "start_time": "2024-04-27T23:25:49.084637Z"
    }
   },
   "source": [
    "# Calculate the word count for each 'Consumer complaint narrative' in the testing data\n",
    "# The word count is calculated by splitting the narrative into words and counting the number of words\n",
    "# The result is stored in a new column 'wdct' in the testing data\n",
    "data_test['wdct'] = data_test['Consumer complaint narrative'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Calculate the sentiment for each 'Consumer complaint narrative' in the testing data\n",
    "# The sentiment is calculated using the TextBlob library, which returns a polarity score between -1 (negative) and 1 (positive)\n",
    "# The result is stored in a new column 'sentiment' in the testing data\n",
    "data_test['sentiment'] = data_test['Consumer complaint narrative'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "\n",
    "# Estimate the accuracy of the word count as a predictor for 'Company public response' using Kendall's tau\n",
    "# The 'wdct' column is the predicted response variable and the 'Company public response' column is the actual response variable\n",
    "wdct_acc = kendall_acc(data_test['wdct'], data_test['Company public response'])\n",
    "\n",
    "# Estimate the accuracy of the sentiment as a predictor for 'Company public response' using Kendall's tau\n",
    "# The 'sentiment' column is the predicted response variable and the 'Company public response' column is the actual response variable\n",
    "sentiment_acc = kendall_acc(data_test['sentiment'], data_test['Company public response'])\n",
    "\n",
    "# Print the accuracy of the word count as a predictor\n",
    "print(wdct_acc)\n",
    "\n",
    "# Print the accuracy of the sentiment as a predictor\n",
    "print(sentiment_acc)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/ktn1hrps3flfg5b_bszm_lk00000gn/T/ipykernel_10933/2858153666.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['wdct'] = data_test['Consumer complaint narrative'].apply(lambda x: len(str(x).split()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc  lower  upper\n",
      "0  47.92  47.27  48.58\n",
      "     acc  lower  upper\n",
      "0  51.26   50.6  51.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/ktn1hrps3flfg5b_bszm_lk00000gn/T/ipykernel_10933/2858153666.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test['sentiment'] = data_test['Consumer complaint narrative'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "fb8c8aab4612c384",
   "metadata": {},
   "source": [
    "########################################\n",
    "# Combine accuracy estimates for a plot\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d2bcad3bad53942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:25:55.936026Z",
     "start_time": "2024-04-27T23:25:55.933228Z"
    }
   },
   "source": [
    "# Concatenate the accuracy dataframes for ngram, vector, ngram+vector, word count, and sentiment into a single dataframe\n",
    "plot_dat = pd.concat([ngram_acc, vec_acc, ngram_vec_acc, wdct_acc, sentiment_acc])\n",
    "\n",
    "# Add a new column 'features' to the dataframe with the names of the feature sets used for each accuracy estimate\n",
    "plot_dat['features'] = ['ngrams', 'w2v', 'ngrams+w2v', 'word count', 'sentiment']\n",
    "\n",
    "# Calculate the error for each accuracy estimate by subtracting the lower bound from the accuracy\n",
    "# Store the result in a new column 'err'\n",
    "plot_dat['err'] = plot_dat['acc'] - plot_dat['lower']\n",
    "\n",
    "# Print the dataframe\n",
    "# This is used to check the final dataframe\n",
    "print(plot_dat)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc  lower  upper    features   err\n",
      "0  67.17  66.55  67.78      ngrams  0.62\n",
      "0  64.11  63.48  64.74         w2v  0.63\n",
      "0  67.52  66.91  68.14  ngrams+w2v  0.61\n",
      "0  47.92  47.27  48.58  word count  0.65\n",
      "0  51.26  50.60  51.91   sentiment  0.66\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "1daad3d6d47e9a62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T23:25:55.996279Z",
     "start_time": "2024-04-27T23:25:55.936476Z"
    }
   },
   "source": [
    "# Import the pyplot module from matplotlib library\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Create a new figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# Create an error bar plot\n",
    "# The 'features' column in the 'plot_dat' DataFrame is used for the y-values\n",
    "# The 'acc' column in the 'plot_dat' DataFrame is used for the x-values\n",
    "# The 'err' column in the 'plot_dat' DataFrame is used for the x-error values\n",
    "# The format of the markers is set to 'o', the color is set to 'b', the line width of the error bars is set to 0.6,\n",
    "# the size of the markers is set to 8, and the length of the error bar caps is set to 10\n",
    "plt.errorbar(y = plot_dat['features'], x = plot_dat['acc'], xerr=plot_dat['err'], fmt=\"o\", color=\"b\", elinewidth=.6, markersize=8, capsize=10)\n",
    "\n",
    "# Turn off the grid\n",
    "plt.grid(False)\n",
    "\n",
    "# Add a vertical line at x=50\n",
    "# The color of the line is set to 'lightgrey' and the line style is set to '-'\n",
    "plt.axvline(x=50, color='lightgrey', linestyle='-')\n",
    "\n",
    "# Add labels to the x and y axes\n",
    "plt.xlabel('Accuracy', fontsize=18)\n",
    "plt.ylabel('Feature set', fontsize=18)\n",
    "\n",
    "# Set the margins of the plot\n",
    "# The x and y margins are set to 0.1\n",
    "plt.margins(0.1, tight=True)\n",
    "\n",
    "# Set the limits of the x-axis\n",
    "# The right limit is set to the maximum accuracy plus the maximum error times 1.02\n",
    "# The left limit is set to the minimum accuracy minus the minimum error times 0.98\n",
    "plt.xlim(right=((max(plot_dat['acc']) + max(plot_dat['err']))) * 1.02,\n",
    "         left=((min(plot_dat['acc']) - min(plot_dat['err']))) * 0.98)\n",
    "\n",
    "# Set the font size of the x and y tick labels\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
